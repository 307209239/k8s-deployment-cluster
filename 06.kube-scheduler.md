# 部署 kube-scheduler 组件
---
#### 创建 kube-scheduler 证书证书签名请求
```
$ cd /root/pki/ssl
$ cat > kube-scheduler-csr.json <<EOF
{
    "CN": "system:kube-scheduler",
    "hosts": [
      "127.0.0.1",
      "192.168.133.128",
      "192.168.133.129",
      "192.168.133.130"
    ],
    "key": {
        "algo": "rsa",
        "size": 2048
    },
    "names": [
      {
        "C": "CN",
        "ST": "BeiJing",
        "L": "BeiJing",
        "O": "system:kube-scheduler",
        "OU": "System"
      }
    ]
}
EOF
```
#### 生成`kube-scheduler`证书和私钥
```
$ cfssl gencert -ca=/etc/kubernetes/ssl/ca.pem \
  -ca-key=/etc/kubernetes/ssl/ca-key.pem \
  -config=/etc/kubernetes/ssl/ca-config.json \
  -profile=kubernetes kube-scheduler-csr.json | cfssljson -bare kube-scheduler
$ ls kube-scheduler*.pem
```
#### 分发`kube-scheduler`证书分发至`master`节点
```
$ export NODE_IPS=(192.168.133.128 192.168.133.129 192.168.133.130)
$ for node_ip in ${NODE_IPS[@]}
  do
    echo ">>> ${node_ip}"
    scp kube-scheduler* ${node_ip}:/etc/kubernetes/ssl
    ssh ${node_ip} "chmod 755 /etc/kubernetes/ssl/kube-scheduler*.pem"
  done
```
#### 创建和分发kubeconfig文件
生成`kubeconfig`文件
```
$ export MASTER_VIP=192.168.133.200
$ export KUBE_APISERVER="https://${MASTER_VIP}:8443"

$ kubectl config set-cluster kubernetes \
  --certificate-authority=/etc/kubernetes/ssl/ca.pem \
  --embed-certs=true \
  --server=${KUBE_APISERVER} \
  --kubeconfig=kube-scheduler.kubeconfig

$ kubectl config set-credentials system:kube-scheduler \
  --client-certificate=kube-scheduler.pem \
  --client-key=kube-scheduler-key.pem \
  --embed-certs=true \
  --kubeconfig=kube-scheduler.kubeconfig

$ kubectl config set-context system:kube-scheduler \
  --cluster=kubernetes \
  --user=system:kube-scheduler \
  --kubeconfig=kube-scheduler.kubeconfig

$ kubectl config use-context system:kube-scheduler --kubeconfig=kube-scheduler.kubeconfig
```
分发`kubeconfig`到所有`master`节点
```
$ export NODE_IPS=(192.168.133.128 192.168.133.129 192.168.133.130)
$ for node_ip in ${NODE_IPS[@]}
  do
    echo ">>> ${node_ip}"
    scp kube-scheduler.kubeconfig ${node_ip}:/etc/kubernetes/
  done
```
#### 创建服务启动文件
创建和分发`kube-scheduler`服务启动文件
```
$ cat > /tmp/kube-scheduler.service <<EOF
[Unit]
Description=Kubernetes Scheduler
Documentation=https://github.com/GoogleCloudPlatform/kubernetes

[Service]
ExecStart=/usr/sbin/kube-scheduler \\
  --address=127.0.0.1 \\
  --bind-address=0.0.0.0 \\
  --kubeconfig=/etc/kubernetes/kube-scheduler.kubeconfig \\
  --leader-elect=true \\
  --alsologtostderr=true \\
  --logtostderr=false \\
  --log-dir=/var/log/kubernetes \\
  --v=2
Restart=on-failure
RestartSec=5
User=root

[Install]
WantedBy=multi-user.target
EOF
```
分发systemd unit文件到所有master节点
```
$ export NODE_IPS=(192.168.133.128 192.168.133.129 192.168.133.130)
$ for node_ip in ${NODE_IPS[@]}
  do
    echo ">>> ${node_ip}"
    scp /tmp/kube-scheduler.service ${node_ip}:/etc/systemd/system/
    ssh root@${node_ip} "sed -i 's/##NODE_IP##/${node_ip}/' /etc/systemd/system/kube-scheduler.service"
    ssh ${node_ip} "systemctl daemon-reload && systemctl enable kube-scheduler && systemctl restart kube-scheduler"
  done
```
检查leader
```
$ kubectl get endpoints kube-scheduler --namespace=kube-system  -o yaml
apiVersion: v1
kind: Endpoints
metadata:
  annotations:
    control-plane.alpha.kubernetes.io/leader: '{"holderIdentity":"k8s-m01_ed9c7fb3-f578-11e8-80ff-000c298e8aad","leaseDurationSeconds":15,"acquireTime":"2018-12-01T14:53:57Z","renewTime":"2018-12-01T14:54:54Z","leaderTransitions":0}'
  creationTimestamp: 2018-12-01T14:53:57Z
  name: kube-scheduler
  namespace: kube-system
  resourceVersion: "13599"
  selfLink: /api/v1/namespaces/kube-system/endpoints/kube-scheduler
  uid: ee4651df-f578-11e8-930d-000c298e8aad
```
提示: 从 `"holderIdentity":"k8s-m01_ed9c7fb3-f578-11e8-80ff-000c298e8aad"` 这看出来选举出的 `kube-scheduler` 是 `k8s-m01`；
#### 检查集群信息
```
$ kubectl get componentstatuses
NAME                 STATUS    MESSAGE             ERROR
scheduler            Healthy   ok                  
controller-manager   Healthy   ok                  
etcd-0               Healthy   {"health":"true"}   
etcd-1               Healthy   {"health":"true"}   
etcd-2               Healthy   {"health":"true"}
```
可以看到 `scheduler` 已处于 `Healthy` 状态；